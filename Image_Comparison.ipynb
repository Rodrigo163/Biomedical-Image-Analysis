{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as iio\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial transformation\n",
    "We'll use OASIS (Open access series of imaging studies). With a large dataset we're gonna have significant variability (intensity scales, object orientation, shape, object placement withing object window). \n",
    "\n",
    "One way to address this is to register images to a predefined position and coordinate system. Per example we can align all images to a template image or atlas.\n",
    "\n",
    "Registration is the process of aligning two images together and it requires making several transformations to an image (shifting, rotating, scaling). It'll align images to template, minimize spatial variability...\n",
    "\n",
    "We'll use affine transformations (preserve points, lines and planes). \n",
    "\n",
    "No good data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translation\n",
    "#Center of image is middle of im.shape\n",
    "com = ndi.center_of_mass(im)\n",
    "\n",
    "#now we calc the dicc bet the current head center and the target center\n",
    "d0 = 128 - com[0] #shape was 256x256\n",
    "d1 = 128 - com[1]\n",
    "xfm = ndi.shift(im, shift = [d0, d1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotation\n",
    "#with 3D image we have to specify rotation place\n",
    "#Rotation might change shape of image, to prevent this pass reshep=False\n",
    "ndi.rotate(im, angle = 25, axes=(0,1), reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-3-563c37df41bb>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-563c37df41bb>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    [0,0,1\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#For more complex transformations we use transformation matrix\n",
    "#Example with identity matrix\n",
    "m = [[1,0,0],\n",
    "    [0,1,0],\n",
    "    [0,0,1]]\n",
    "xfm = ndi.affine_transform(im, mat)\n",
    "\n",
    "#shifting and rescaling\n",
    "m = [[0.8, 0, -20], \n",
    "     [0, 0.8, -10], \n",
    "     [0,0,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling and interpolation\n",
    "Differences in sampling rates can hurt analysis. \n",
    "Resampling is slicing data into new arangement. It's different from cropping in which the field of view doesn't change.\n",
    "\n",
    "In downsampling we'll merge information across multiple pixels in order to reduce image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/21 files (4.8%15/21 files (71.4%21/21 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 21/21  (100.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21, 256, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we create the volume image we'll analyse\n",
    "vol = iio.volread('sunnybrook-cardiac-mr/SCD2001_000')\n",
    "vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_dn = ndi.zoom(vol, zoom=0.5) #reduces number of elements on each axis by half\n",
    "vol_dn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also upsample but we have to keep in mind that even if we're adding new pixels we're not adding new info, so the resolution will not improve. We'll use it to standardize sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 512, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_up = ndi.zoom(vol, 2)\n",
    "vol_up.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling stitches together grid points to model the space between points and model the data that was not originally there. This is done by interpolation. For high order interpolation scipy used B-spline interpolation. Order of the spline functions is from 1 to 5.\n",
    "\n",
    "The higher the order the more time the computation will take. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center and level image\n",
    "xfm = ndi.shift(____, shift=____)\n",
    "xfm = ndi.rotate(____, angle=____, reshape=____)\n",
    "\n",
    "# Resample image\n",
    "im_dn = ndi.zoom(xfm, zoom=____)\n",
    "im_up = ____\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "axes[0].imshow(im_dn)\n",
    "____\n",
    "\n",
    "# Upsample \"im\" by a factor of 4\n",
    "up0 = ndi.zoom(____, zoom=____, order=____)\n",
    "up5 = ____\n",
    "\n",
    "# Print original and new shape\n",
    "print('Original shape:', ____)\n",
    "print('Upsampled shape:', ____)\n",
    "\n",
    "# Plot close-ups of the new images\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(up0[128:256, 128:256])\n",
    "axes[1].imshow(____)\n",
    "format_and_render_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing images\n",
    "To directly compare two images we need measured of image similarity. The goal will be to define a metric of similarity between two images. \n",
    "\n",
    "We'll use cost functions (like mean square error) and objective (union of both) functions (produce metrics to be minimized and max. respectively).\n",
    "\n",
    "We'll first use mean absolute error to calc similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1\n",
    "im2\n",
    "err = im1 - im2\n",
    "plt.imshow(err)\n",
    "abs_err = np.abs(err)\n",
    "plt.imshow(abs_err)\n",
    "mae = np.mean(abs_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to minimize the cost function (=0 would mean that both images were identical). We want to do this by shifting/rotating/transforming one or both images.\n",
    "\n",
    "A problem with this measure is that tissues with higher intensity will contribute more to the measure than others. \n",
    "\n",
    "An additional measure is to compare the union of the masks (remember that masks are boolean so no intensity involved).\n",
    "\n",
    "Intersection of the union = intersection/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = im1 > 0\n",
    "mask2 = im2 > 0\n",
    "intsxn = mask1 & mask2\n",
    "plt.imshow(intsxn)\n",
    "\n",
    "union = mask1 | mask2\n",
    "plt.imshow(union)\n",
    "\n",
    "iou = intsxn.sum() / union.sum()\n",
    "\n",
    "iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_of_union(im1, im2):\n",
    "    i = np.logical_and(im1, im2)\n",
    "    u = np.logical_or(im1, im2)\n",
    "    return i.sum() / u.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing measurements\n",
    "![title](Capture.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the brains of men and women the same?\n",
    "Hypothesis testing with null hypothesis (two population's mean brain volumes are equal) and t-test\n",
    "scipy.stats.ttest_ind()\n",
    "\n",
    "If we had all our info in a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_m = df.loc[df.sex == 'M', 'brain_vol']\n",
    "brain_f = df.loc[df.sex == 'F', 'brain_vol']\n",
    "\n",
    "#run t-test\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "results = ttes_ind(brain_m, brain_f)\n",
    "# this returns in the test statistic and the p value (prob of null hypo. being true)\n",
    "#large t-statistic and low p-value suggests that there is a significant difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated measurements\n",
    "We need to fill up the context in which this results in aquired. Brains fill skulls, which are proportional to body size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-958386bb5779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'brain_vol'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'skull_vol'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#this shows that those two categories have high correlation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[['brain_vol', 'skull_vol']].corr()\n",
    "#this shows that those two categories have high correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for this we can normalize our data with respect to skull volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a20b16e497b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'brain_norm'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbrain_vol\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskull_vol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# we can then repeat the t-test for the normalized values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['brain_norm'] = df.brain_vol / df.skull_vol\n",
    "# we can then repeat the t-test for the normalized values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new results show that size, not gender was likely driving the original results. \n",
    "![title](Capture1.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
